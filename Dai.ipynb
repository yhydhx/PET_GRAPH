{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Dai.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLzi70Nb4tKC","executionInfo":{"status":"ok","timestamp":1620063578173,"user_tz":-120,"elapsed":1545,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}},"outputId":"d64dae30-bc7f-4828-e59e-d12768681228"},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import sys\n","import os\n","import torchvision\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import matplotlib.pyplot as plt\n","import imp\n","import importlib\n","device = torch.device('cuda')\n","import copy\n","from IPython.display import  HTML, display\n","color=['tab:blue','tab:orange','tab:green','tab:red','tab:purple','tab:brown','tab:pink','tab:gray','tab:olive','tab:cyan']\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IDqvjFV6mYS","executionInfo":{"status":"ok","timestamp":1620063580268,"user_tz":-120,"elapsed":731,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}},"outputId":"ee2b2e54-806b-4345-b9ad-f354abb4d2d4"},"source":["%cd /content/drive/My\\ Drive/dai/PET_GRAPH/\n","!pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/dai/PET_GRAPH\n","/content/drive/My Drive/dai/PET_GRAPH\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ZI_ZidO5EGG","executionInfo":{"status":"ok","timestamp":1620063584419,"user_tz":-120,"elapsed":880,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}}},"source":["from multi_search_graph import Train"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ji5wJmE5TmG","executionInfo":{"status":"ok","timestamp":1620063585691,"user_tz":-120,"elapsed":637,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}}},"source":["test = Train()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QJGc9tVe6LvZ","executionInfo":{"status":"ok","timestamp":1620063588319,"user_tz":-120,"elapsed":1140,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}},"outputId":"d8653f57-c86f-4525-f177-13f661ce826e"},"source":["train_data, train_label, test_data, test_label, L, lmax, A, candidate , old_A = test.prepare(test.dataset);\n","a=1"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(419, 120)\n","(419,)\n","2750\n","candidate number:  1265\n","(228, 120)\n","(99, 120)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OnXdM8EbFzrL","executionInfo":{"status":"ok","timestamp":1620063591793,"user_tz":-120,"elapsed":696,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}}},"source":["number_candidate=len(candidate)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j-qa-IPHDrKa"},"source":["# NN"]},{"cell_type":"code","metadata":{"id":"5KtVmaGwDr2W","executionInfo":{"status":"ok","timestamp":1620064608203,"user_tz":-120,"elapsed":849,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}}},"source":["class policy(torch.nn.Module):\n","    def __init__(self,input_size,output_size):\n","        super(policy, self).__init__()\n","        self.linear1 = torch.nn.Linear(input_size,2000)\n","        self.linear2 = torch.nn.Linear(2000,800)\n","        self.linear3 = torch.nn.Linear(800,200)\n","        self.linear4 = torch.nn.Linear(200,500)\n","        self.linear5_add = torch.nn.Linear(500,output_size)\n","        self.linear5_remove = torch.nn.Linear(500,output_size)\n","        self.act1= nn.ReLU()\n","        self.act2= nn.ReLU()\n","        self.act3= nn.ReLU()\n","        self.act4= nn.ReLU()\n","        self.sma=nn.Softmax()\n","        self.smm=nn.Softmax()\n","\n","    def forward(self, x):\n","        out= self.linear1(x)\n","        out = self.act1(out)\n","        out= self.linear2(out)\n","        out = self.act2(out)\n","        out = self.linear3(out)\n","        out = self.act3(out)\n","        out = self.linear4(out)\n","        out = self.act4(out)\n","        out_add = self.linear5_add(out)\n","        out_add=self.sma(out_add)\n","        out_remove = self.linear5_remove(out)\n","        out_remove=self.smm(out_remove)\n","        return [out_add,out_remove]"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zACoPbviOYMT"},"source":["## env"]},{"cell_type":"code","metadata":{"id":"HYrhEIvWEv4Z","executionInfo":{"status":"ok","timestamp":1620066181040,"user_tz":-120,"elapsed":1017,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}}},"source":["import numpy as np\n","from multi_search_graph import Train\n","class DiaEnv():\n","    def __init__(self,params=1):\n","        self.range = 1000  # Randomly selected number is within +/- this value\n","        self.bounds = 10000\n","        self.runtrain=Train()\n","        self.runtrain.set_params(params)\n","        train_data, train_label, test_data, test_label, L, lmax, A, candidate , old_A = self.runtrain.prepare(self.runtrain.dataset)\n","        self.candiatelen=len(candidate)\n","        self.p=200.0/self.candiatelen\n","        obs = [np.random.choice([0,1],p=[1-self.p,self.p]) for _ in range(len(candidate))]\n","        self.observation = obs\n","    def set_params(params):\n","        self.runtrain.set_params(params)\n","    def reset(self):\n","        obs = [np.random.choice([0,1],p=[1-self.p,self.p]) for _ in range(self.candiatelen)]\n","        self.observation = obs\n","        return self.observation\n","    def step(self, action,Val=True):\n","        if action[0]>=0:\n","            self.observation[action[0]]=1\n","        if action[1]>=0:\n","            self.observation[action[1]]=0\n","        if Val:\n","            new_A = self.runtrain.action_graph(self.observation)\n","            reward = self.runtrain.train_one(new_A)\n","        else:\n","            reward=0\n","        return self.observation, reward"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWDJorc5SI8f","outputId":"6db1c15c-2785-44e4-fe7b-71f62a60a9ea"},"source":["Iftrain=True\n","\n","Ifloadpolicy=False\n","Ifloadstate=False\n","num_episode = 10000\n","init_state_step=1000000\n","learning_rate = 0.001\n","gamma = 0.99\n","batch_size=10\n","\n","\n","env = DiaEnv(params=1)\n","candiatelen=env.candiatelen\n","if Ifloadpolicy:\n","    model=torch.load('/content/drive/My Drive/Dai/PET_GRAPH/policy.pt')\n","else:  \n","    model = policy(candiatelen,candiatelen).to(device)\n","\n","\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","alpha=1.0/candiatelen\n","\n","for e in range(num_episode):\n","    print(\"episode:\",e)\n","    ###new state\n","    if e%init_state_step==0:\n","        if Ifloadstate:\n","            state=torch.load('/content/drive/My Drive/Dai/PET_GRAPH/state.pt')\n","        else:  \n","            state = env.reset()\n","            state = torch.from_numpy(np.array(state)).float().to(device)\n","            state = Variable(state).to(device)\n","            state.require_grad=False\n","\n","\n","\n","\n","\n","    \n","    state_pool = []\n","    action_pool = []\n","    reward_pool = []\n","    for t in range(batch_size):\n","        [probs_add,probs_remove] = model(state.reshape([1,-1]))\n","\n","        statemask=state.reshape([1,-1]).cpu().detach().numpy()[0]\n","        #probs_add=probs_add.cpu().detach_().numpy().reshape(-1)\n","        #probs_remove=probs_remove.cpu().detach_().numpy().reshape(-1)\n","\n","        #####pick action\n","        pos_add=np.where(statemask ==0)[0]\n","        probs_add=probs_add[0].cpu().detach().numpy()\n","        p_add=probs_add[pos_add]\n","        p_add=p_add/p_add.sum()\n","        action_add=int(np.random.choice(pos_add, 1, p=p_add)[0])\n","        \n","\n","        pos_remove=np.where(statemask ==1)[0]\n","        probs_remove=probs_remove[0].cpu().detach().numpy()\n","        p_remove=probs_remove[pos_remove]\n","        p_remove=p_remove/p_remove.sum()\n","        action_remvoe=int(np.random.choice(pos_remove, 1, p=p_remove)[0])\n","        ## threshold\n","        if alpha>probs_add[action_add]:\n","            action_add=-1\n","        if alpha>probs_remove[action_remvoe]:\n","            action_remvoe=-1\n","\n","        \n","        action=[int(action_add),int(action_remvoe)]\n","        \n","        #next_state, reward, = state,1\n","        next_state, reward, = env.step(action,Val=Iftrain)\n","        print(f'Action:{action},Reward:{reward}')\n","        next_state=torch.from_numpy(np.array(next_state)).float().to(device)\n","        next_state= Variable(next_state).to(device)\n","        next_state.require_grad=False\n","    \n","        state_pool.append(state.clone().detach())\n","        action_pool.append(action)\n","        reward_pool.append(reward)\n","        state = next_state\n","    print('updating policy')\n","\n","    # Update policy\n","    if Iftrain:\n","\n","\n","        # Normalize reward\n","        reward_mean = np.mean(reward_pool)\n","        reward_std = np.std(reward_pool)\n","        for i in range(batch_size):\n","            reward_pool[i] = (reward_pool[i] - reward_mean) / reward_std\n","\n","        # Gradient Desent\n","        optimizer.zero_grad()\n","        criterion = nn.NLLLoss()\n","        for i in range(batch_size):\n","            state = state_pool[i]\n","            reward = reward_pool[i]\n","            [probs_add,probs_remove] = model(state)\n","            target_add=Variable(torch.tensor([action_pool[i][0]])).to(device)\n","            target_remove=Variable(torch.tensor([action_pool[i][1]])).to(device)\n","            loss = criterion(probs_add,target_add) * reward+  criterion(probs_remove,target_remove) * reward\n","            loss.backward()\n","        optimizer.step()\n","\n","        state_pool = []\n","        action_pool = []\n","        reward_pool = []\n","        torch.save(state, '/content/drive/My Drive/Dai/PET_GRAPH/state.pt')\n","        torch.save(policy,'/content/drive/My Drive/Dai/PET_GRAPH/policy.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(419, 120)\n","(419,)\n","2750\n","candidate number:  1265\n","(228, 120)\n","(99, 120)\n","episode: 0\n","528\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n","  self._set_intXint(row, col, x.flat[0])\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          NC       0.85      0.61      0.71        28\n","        LMCI       0.43      0.67      0.52        30\n","        EMCI       0.59      0.46      0.52        41\n","\n","    accuracy                           0.57        99\n","   macro avg       0.62      0.58      0.58        99\n","weighted avg       0.62      0.57      0.57        99\n","\n","[[17  6  5]\n"," [ 2 20  8]\n"," [ 1 21 19]]\n","Action:[-1, -1],Reward:56.56565656565657\n","528\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n","  self._set_intXint(row, col, x.flat[0])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ds7MIVYxjik4","executionInfo":{"status":"ok","timestamp":1620067759950,"user_tz":-120,"elapsed":1345,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}},"outputId":"6f05caeb-d4d4-4f96-c807-d49f6ac810fc"},"source":["next_state"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," ...]"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Seag5InQYdiI","executionInfo":{"status":"ok","timestamp":1620065339569,"user_tz":-120,"elapsed":725,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}},"outputId":"0baa9e24-4dd1-408a-d447-f2becca07a74"},"source":["pos_add=np.where(statemask ==0)[0]\n","p_add=probs_add[0].cpu().detach().numpy()[pos_add]\n","p_add=p_add/p_add.sum()\n","action_add=np.random.choice(pos_add, 1, p=p_add)[0]\n","\n","\n","pos_remove=np.where(statemask ==1)[0]\n","p_remove=probs_remove[0].cpu().detach().numpy()[pos_remove]\n","p_remove=p_remove/p_remove.sum()\n","action_remvoe=np.random.choice(pos_remove, 1, p=p_remove)[0]"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1181])"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BQ6iwXzagsa","executionInfo":{"status":"ok","timestamp":1620065373313,"user_tz":-120,"elapsed":975,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}},"outputId":"32caa0dd-1d29-4494-e7bf-87be0f3fab88"},"source":["anp.random.choice(pos0, 1, p=p0)[0]"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["380"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9Uyq49PZZW_","executionInfo":{"status":"ok","timestamp":1620064991661,"user_tz":-120,"elapsed":1380,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}},"outputId":"d4b6ca88-2369-473f-c190-b99ebe3c56b2"},"source":["probs_add[0].cpu().detach().numpy()[pos0]"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0008, 0.0008, 0.0008,  ..., 0.0008, 0.0008, 0.0008], device='cuda:0',\n","       grad_fn=<IndexBackward>)"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imFMDRhgY70R","executionInfo":{"status":"ok","timestamp":1620065154884,"user_tz":-120,"elapsed":912,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"}},"outputId":"bfbc363d-2b41-4c8c-f902-35bbcb7c3d7b"},"source":["np.arange(10)"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEa14V7TDZHb","executionInfo":{"elapsed":522825,"status":"ok","timestamp":1618043171362,"user":{"displayName":"施成","photoUrl":"","userId":"14707086256107758378"},"user_tz":-120},"outputId":"f1f93e27-4bd9-4cda-e50d-cf1a215097eb"},"source":["#state=torch.load('/content/drive/My Drive/Dai/PET_GRAPH/state9.pt')\n","action=state.cpu().detach_().numpy().reshape(-1)\n","action=state.cpu().detach_().numpy().reshape(-1)\n","print(action.sum())\n","test.set_params(1)\n","new_A = test.action_graph(action)\n","acc = test.train_top3(new_A)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n","  self._set_intXint(row, col, x.flat[0])\n"],"name":"stderr"}]}]}