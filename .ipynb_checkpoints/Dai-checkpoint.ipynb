{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1556,
     "status": "ok",
     "timestamp": 1618041394269,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "nLzi70Nb4tKC",
    "outputId": "2a01ad7f-d652-48e0-8790-0b8d44f567e0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b1b149863a5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import imp\n",
    "import importlib\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "from IPython.display import HTML, display\n",
    "color=['tab:blue','tab:orange','tab:green','tab:red','tab:purple','tab:brown','tab:pink','tab:gray','tab:olive','tab:cyan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1618041394270,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "8IDqvjFV6mYS",
    "outputId": "1d38598f-66c7-4a01-a0d9-067ebf5939a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Dai/PET_GRAPH\n",
      "/content/drive/MyDrive/Dai/PET_GRAPH\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/Dai/PET_GRAPH/\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1904,
     "status": "ok",
     "timestamp": 1618041394942,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "1ZI_ZidO5EGG"
   },
   "outputs": [],
   "source": [
    "from multi_search_graph import Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1769,
     "status": "ok",
     "timestamp": 1618041394944,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "1ji5wJmE5TmG"
   },
   "outputs": [],
   "source": [
    "test = Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1618041394944,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "QJGc9tVe6LvZ",
    "outputId": "d927ac9d-a847-4504-83f7-e1e3d6297c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419, 120)\n",
      "(419,)\n",
      "2588\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, test_data, test_label, L, lmax, A, candidate , old_A = test.prepare(test.dataset);\n",
    "a=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-qa-IPHDrKa"
   },
   "source": [
    "# Siren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1618041395397,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "5KtVmaGwDr2W"
   },
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "   \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "            self.net.append(nn.Softmax())\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(False) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        #return output, coords\n",
    "        return output        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zACoPbviOYMT"
   },
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1618041397519,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "HYrhEIvWEv4Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multi_search_graph import Train\n",
    "class DiaEnv():\n",
    "    def __init__(self,params=1,p=200.0/1555):\n",
    "        self.range = 1000  # Randomly selected number is within +/- this value\n",
    "        self.bounds = 10000\n",
    "        self.runtrain=Train()\n",
    "        self.p=p\n",
    "        self.runtrain.set_params(params)\n",
    "        train_data, train_label, test_data, test_label, L, lmax, A, candidate , old_A = self.runtrain.prepare(self.runtrain.dataset)\n",
    "        self.candiatelen=len(candidate)\n",
    "        obs = [np.random.choice([0,1],p=[1-p,p]) for _ in range(len(candidate))]\n",
    "        self.observation = obs\n",
    "    def set_params(params):\n",
    "        self.runtrain.set_params(params)\n",
    "\n",
    "    def reset(self):\n",
    "        obs = [np.random.choice([0,1],p=[1-self.p,self.p]) for _ in range(self.candiatelen)]\n",
    "        self.observation = obs\n",
    "        return self.observation\n",
    "    def step(self, action,Val=True):\n",
    "        self.observation[action[0]]=1\n",
    "        self.observation[action[1]]=0\n",
    "        if Val:\n",
    "            new_A = self.runtrain.action_graph(action)\n",
    "            reward = self.runtrain.train_top1(new_A)\n",
    "        else:\n",
    "            reward=0\n",
    "        return self.observation, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1618041399844,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "h7fdeqHVhXDe"
   },
   "outputs": [],
   "source": [
    "def randompick(probs):\n",
    "    pd=np.random.rand()\n",
    "    for i in range(len(probs)):\n",
    "        pd=pd-probs[i]\n",
    "        if pd<0:\n",
    "            break\n",
    "    pick=i-1\n",
    "    return pick\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2202,
     "status": "ok",
     "timestamp": 1618041433285,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "BWDJorc5SI8f",
    "outputId": "ba9722f1-2dc3-4ab5-a347-2e5e5649d659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419, 120)\n",
      "(419,)\n",
      "2932\n",
      "111 1555\n",
      "episode 0\n",
      "[592, 178]\n",
      "[1508, 608]\n",
      "[592, 1174]\n",
      "[592, 119]\n",
      "[592, 577]\n",
      "[592, 830]\n",
      "[592, 1462]\n",
      "[592, 1366]\n",
      "[592, 1349]\n",
      "[592, 681]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 1\n",
      "[592, 865]\n",
      "[592, 247]\n",
      "[592, 763]\n",
      "[592, 1443]\n",
      "[592, 659]\n",
      "[592, 470]\n",
      "[592, 976]\n",
      "[592, 741]\n",
      "[592, 703]\n",
      "[592, 1249]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 2\n",
      "[592, 1251]\n",
      "[592, 1096]\n",
      "[592, 93]\n",
      "[592, 965]\n",
      "[592, 1550]\n",
      "[592, 70]\n",
      "[592, 712]\n",
      "[1389, 1273]\n",
      "[592, 824]\n",
      "[592, 1537]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 3\n",
      "[592, 1394]\n",
      "[592, 802]\n",
      "[592, 132]\n",
      "[592, 393]\n",
      "[592, 1325]\n",
      "[592, 407]\n",
      "[592, 677]\n",
      "[592, 1004]\n",
      "[320, 370]\n",
      "[301, 502]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 4\n",
      "[301, 580]\n",
      "[301, 1367]\n",
      "[301, 1264]\n",
      "[301, 1153]\n",
      "[301, 552]\n",
      "[301, 252]\n",
      "[301, 925]\n",
      "[301, 728]\n",
      "[301, 649]\n",
      "[301, 257]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 5\n",
      "[301, 623]\n",
      "[301, 401]\n",
      "[1521, 1388]\n",
      "[1521, 865]\n",
      "[1521, 488]\n",
      "[1521, 1370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1521, 748]\n",
      "[1521, 1453]\n",
      "[1521, 1070]\n",
      "[1521, 1073]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 6\n",
      "[1521, 473]\n",
      "[1521, 1055]\n",
      "[1521, 1331]\n",
      "[1521, 194]\n",
      "[1521, 628]\n",
      "[1521, 1540]\n",
      "[1521, 997]\n",
      "[1521, 397]\n",
      "[1521, 112]\n",
      "[1521, 841]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 7\n",
      "[1521, 1298]\n",
      "[1521, 932]\n",
      "[1521, 1201]\n",
      "[1521, 1537]\n",
      "[1521, 153]\n",
      "[1521, 733]\n",
      "[1521, 1351]\n",
      "[1521, 48]\n",
      "[1521, 435]\n",
      "[1521, 62]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 8\n",
      "[1521, 1151]\n",
      "[1521, 760]\n",
      "[1521, 1371]\n",
      "[1521, 1119]\n",
      "[1521, 671]\n",
      "[1521, 1202]\n",
      "[1521, 860]\n",
      "[1521, 1286]\n",
      "[435, 925]\n",
      "[301, 296]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "episode 9\n",
      "[301, 238]\n",
      "[301, 1313]\n",
      "[301, 491]\n",
      "[301, 1439]\n",
      "[301, 170]\n",
      "[301, 1505]\n",
      "[301, 145]\n",
      "[301, 859]\n",
      "[301, 1091]\n",
      "[301, 971]\n",
      "Reward [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from itertools import count\n",
    "episode_durations = []\n",
    "\n",
    "#plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Parameters\n",
    "Iftrain=True\n",
    "Ifloadpolicy=False\n",
    "Ifloadstate=False\n",
    "num_episode = 10\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "gamma = 0.99\n",
    "\n",
    "env = DiaEnv(params=1)\n",
    "le=env.candiatelen\n",
    "print(111,le)\n",
    "if Ifloadpolicy:\n",
    "    policy_net_add=torch.load('/content/drive/My Drive/Dai/PET_GRAPH/policy_net_add8.pt')\n",
    "    policy_net_remove=torch.load('/content/drive/My Drive/Dai/PET_GRAPH/policy_net_remove8.pt')\n",
    "else:  \n",
    "    policy_net_add = Siren(in_features=le, out_features=le, hidden_features=500, \n",
    "                    hidden_layers=3, outermost_linear=True).to(device)\n",
    "    policy_net_remove = Siren(in_features=le, out_features=le, hidden_features=500, \n",
    "                    hidden_layers=3, outermost_linear=True).to(device)\n",
    "\n",
    "\n",
    "if Ifloadstate:\n",
    "    state=torch.load('/content/drive/My Drive/Dai/PET_GRAPH/state9.pt')\n",
    "else:  \n",
    "    state = env.reset()\n",
    "    state = torch.from_numpy(np.array(state)).float().to(device)\n",
    "    state = Variable(state).to(device)\n",
    "\n",
    "\n",
    "optimizer_add = torch.optim.RMSprop(policy_net_add.parameters(), lr=learning_rate)\n",
    "optimizer_remove = torch.optim.RMSprop(policy_net_add.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for e in range(num_episode):\n",
    "    print(\"episode\",e)\n",
    "    state_pool = []\n",
    "    action_pool = []\n",
    "    reward_pool = []\n",
    "    for t in range(batch_size):\n",
    "        probs_add = policy_net_add(state.reshape([1,-1])).to(device)\n",
    "        probs_add_np=probs_add.cpu().detach_().numpy().reshape(-1)\n",
    "        action1  = randompick(probs_add_np)\n",
    "\n",
    "\n",
    "        probs_remove = policy_net_remove(state.reshape([1,-1])).to(device)\n",
    "        probs_remove_np=probs_remove.cpu().detach_().numpy().reshape(-1)\n",
    "        action0  = randompick(probs_remove_np)\n",
    "        action=[int(action1),int(action0)]\n",
    "        print(action)\n",
    "        #next_state, reward, = state,1\n",
    "        next_state, reward, = env.step(action,Val=Iftrain)\n",
    "        next_state=torch.from_numpy(np.array(next_state)).float().to(device)\n",
    "        next_state= Variable(next_state).to(device)\n",
    "        state_pool.append(state)\n",
    "        action_pool.append(action)\n",
    "        reward_pool.append(reward)\n",
    "        state = next_state\n",
    "    print('Reward',reward_pool)\n",
    "\n",
    "    # Update policy\n",
    "    if e > 0 and e % batch_size == 0 and Iftrain:\n",
    "\n",
    "\n",
    "        # Normalize reward\n",
    "        reward_mean = np.mean(reward_pool)\n",
    "        reward_std = np.std(reward_pool)\n",
    "        for i in range(batch_size):\n",
    "            reward_pool[i] = (reward_pool[i] - reward_mean) / reward_std\n",
    "\n",
    "        # Gradient Desent\n",
    "        optimizer_add.zero_grad()\n",
    "        optimizer_remove.zero_grad()\n",
    "        criterion = nn.NLLLoss()\n",
    "        for i in range(batch_size):\n",
    "            state = state_pool[i]\n",
    "            reward = reward_pool[i]\n",
    "            probs_add = policy_net_add(state)\n",
    "            probs_remove = policy_net_remove(state)\n",
    "            target_add=Variable(torch.tensor([action_pool[i][0]])).to(device)+1\n",
    "            target_remove=Variable(torch.tensor([action_pool[i][1]])).to(device)+1\n",
    "            loss_add = criterion(probs_add.reshape(1,-1),target_add) * reward  # Negtive score function x reward\n",
    "            loss_remove = criterion(probs_remove.reshape(1,-1),target_remove) * reward\n",
    "            loss_add.backward()\n",
    "            loss_remove.backward()\n",
    "\n",
    "        optimizer_add.step()\n",
    "        optimizer_remove.step()\n",
    "\n",
    "        state_pool = []\n",
    "        action_pool = []\n",
    "        reward_pool = []\n",
    "        torch.save(state, '/content/drive/My Drive/Dai/PET_GRAPH/state10.pt')\n",
    "        torch.save(policy_net_add,'/content/drive/My Drive/Dai/PET_GRAPH/policy_net_add10.pt')\n",
    "        torch.save(policy_net_remove,'/content/drive/My Drive/Dai/PET_GRAPH/policy_net_remove10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522825,
     "status": "ok",
     "timestamp": 1618043171362,
     "user": {
      "displayName": "施成",
      "photoUrl": "",
      "userId": "14707086256107758378"
     },
     "user_tz": -120
    },
    "id": "bEa14V7TDZHb",
    "outputId": "f1f93e27-4bd9-4cda-e50d-cf1a215097eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "#state=torch.load('/content/drive/My Drive/Dai/PET_GRAPH/state9.pt')\n",
    "action=state.cpu().detach_().numpy().reshape(-1)\n",
    "action=state.cpu().detach_().numpy().reshape(-1)\n",
    "print(action.sum())\n",
    "test.set_params(1)\n",
    "new_A = test.action_graph(action)\n",
    "acc = test.train_top3(new_A)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMhepfvE3UOjjoVx8d8qfYd",
   "machine_shape": "hm",
   "name": "Dai.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
